# Machine Learning Index

> First draft inspired by: https://github.com/alirezadir/machine-learning-interview-enlightener/blob/main/ml-breadth.md

## Algorithms categorization

- [ ] Supervised /Unsupervised / Weakly supervised
- [ ] Classification / Regression / Clustering
- [ ] Parametric vs Non parametric
- [ ] Linear vs Nonlinear

## Supervised Learning
- [ ] Linear Algorithms
  - [ ] Linear Regression
  - [ ] Logistic Regression
  - [ ] SVMs
  - [ ] LDA
  - [ ] ...
- [ ] Decision Trees
- [ ] Ensemble methods
  - [ ] Bagging/Boosting/Stacking
  - [ ] Random Forest
  - [ ] AdaBoost
  - [ ] GBM
  - [ ] XGBoost
- [ ] How to choose a ML Algorithm? Graph-like tree
- [ ] Optimization
  - [ ] ERM paradigm
  - [ ] Gradient Descent
  - [ ] SGD
  - [ ] Momentum
  - [ ] Nestervo Momentum
  - [ ] RMSProp
  - [ ] Adam
- [ ] Loss functions
  - [ ] Logistic loss function
  - [ ] Cross Entropy
  - [ ] Hinge Loss
  - [ ] KL loss
- [ ] Model evaluation
  - [ ] Confusion MAtrix ecc
  - [ ] ROC / AUC
  - [ ] MAE / MSE ecc
- [ ] Model selection
  - [ ] Cross Validation
  - [ ] K-Fold CV


## Unsupervised Learning
- [] Clustering
  - Centroid based algos - KMeans
  - Connectivity - Hierachical clusteing
  - Density models - DBScan
- Gaussian Mixture Models
- LSA
- Hidden Markov Models
- Dimensionality Reduction
  - PCA
  - ICA
  - LDA
  - tSNE


## Bias Variance
- [ ] Bias Variance explained
- [ ] Regularization
- [ ] Feature selection
  - [ ] ..
  - [ ] ..

## Sampling and Resampling
- [ ] Sampling
  - [ ] Uniform 
  - [ ] Reservoir
  - [ ] Stratified
- [ ] Resampling
  - [ ] Over
    - [ ] Random
    - [ ] SMOTE
    - [ ] ...
  - [ ] Under
    - [ ] Random
    - [ ] ...
  - [ ] Under/Over
    - [ ] SMOTEENN
    - [ ] ...

##Â Feature engineering

- [ ] Outliers
  - [ ] ...
  - [ ] ...
- [ ] Missing data
  - [ ] ...
  - [ ] ..
- [ ] Distribution
  - [ ] ..
  - [ ] ..
- [ ] Normalization
  - [ ] ...
  - [ ] ..